{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40647519-64ff-43ce-ba3e-5f5523690ca5",
   "metadata": {},
   "source": [
    "Dieser Kurs basiert auf den [Langgraph Tutorials](https://github.com/langchain-ai/langgraph/tree/main/docs/docs/tutorials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c3f9af-507e-4e1c-a6a3-b3d9e3fde73d",
   "metadata": {},
   "source": [
    "# üöÄ Vom Sprachmodell zum Chatbot\n",
    "\n",
    "Mit modernen Sprachmodellen kann man sich fast wie mit einem Menschen unterhalten und sie k√∂nnen einem bei vielen Problemen helfen ‚Äì etwa beim Programmieren oder Schreiben von Texten.\n",
    "Sie haben ein umfangreiches Wissen aus allgemein verf√ºgbaren Dokumenten, mit denen sie trainiert wurden.\n",
    "\n",
    "Wenn es um sehr aktuelle Themen oder Fragen in einem speziellen Kontext geht, fehlen den Sprachmodellen die n√∂tigen Informationen.\n",
    "Mittlerweile gibt es die M√∂glichkeit, diese Informationen \"nachzuliefer\". Das nennt sich dann *Retrieval Augmented Generation*.\n",
    "\n",
    "In diesem Tutorial werden wir einen Chatbot erstellen, der:\n",
    "\n",
    "- [ ] H√§ufige Fragen durch Internetsuche beantworten kann.  \n",
    "- [ ] Den Gespr√§chsfaden √ºber Fragen hinweg aufrechterh√§lt.  \n",
    "- [ ] Fragen zu eigenen Dokumenten beantworten kann, etwa dem Koalitionsvertrag zwischen CDU und SPD oder den Werken von Shakespeare.\n",
    "\n",
    "Dabei verwenden wir die Bibliothek [Langgraph](https://github.com/langchain-ai/langgraph), mit der das sehr einfach funktioniert.\n",
    "\n",
    "Wir beginnen mit einem grundlegenden Chatbot und f√ºgen schrittweise komplexere Funktionen hinzu. \n",
    "Lass uns loslegen!! üåü"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72c038e-e208-4aef-86eb-21a2b07f7abe",
   "metadata": {},
   "source": [
    "## N√∂tige Software installieren\n",
    "\n",
    "Die folgenden beiden Zellen installieren ein paar ben√∂tigte Python-Bibliotheken und laden ein paar vertrauliche Konfigurationsdaten (API-Schl√ºssel): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484918ab-ec39-4ece-a453-3b36ef7412c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --upgrade --quiet dotenv langchain langgraph langsmith langchain-community langchain_chroma langchain_openai langchain-unstructured langchain-docling unstructured-client unstructured \"unstructured[pdf]\" python-magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260ca1a3-4bc2-4d53-b41f-807f77315dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd4e799-a137-4723-b639-674a0cf9d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%dotenv /home/archive/FerienkursKI/.env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485f8b72-8519-4033-9291-b16d76d0269a",
   "metadata": {},
   "source": [
    "# Teil 1: Erstelle einen grundlegenden Chatbot\n",
    "\n",
    "Zun√§chst werden wir einen einfachen Chatbot mit LangGraph erstellen. Dieser Chatbot wird direkt auf Benutzeranfragen antworten. \n",
    "Obwohl er einfach ist, veranschaulicht er die Kernkonzepte von LangGraph. Am Ende dieses Abschnitts wirst du einen rudiment√§ren Chatbot erstellt haben.\n",
    "\n",
    "Beginne mit der Erstellung eines `StateGraph`. Ein `StateGraph`-Objekt definiert die Struktur unseres Chatbots als \"Zustandsmaschine\". \n",
    "Wir werden Knoten hinzuf√ºgen, um das **LLM** (Large Language Model) und Funktionen darzustellen, die unser Chatbot aufrufen kann, sowie Kanten, um anzugeben, wie der Bot zwischen diesen Funktionen wechseln soll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4556bd7-5d88-4974-907d-b48688160856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf375ec0-e19a-432f-a6e6-82885e789e73",
   "metadata": {},
   "source": [
    "Unser Graph kann nun zwei wichtige Aufgaben erledigen:\n",
    "\n",
    "1. Jeder Knoten kann den aktuellen Zustand als Eingabe empfangen und eine Aktualisierung des Zustands ausgeben.\n",
    "2. Aktualisierungen der Nachrichten werden an die bestehende Liste angeh√§ngt, anstatt sie zu √ºberschreiben. Dies geschieht dank der vorgefertigten `add_messages`-Funktion, die mit der annotierten Syntax verwendet wird."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a9017a-a645-4bd6-87dc-e78693358c6f",
   "metadata": {},
   "source": [
    "F√ºge als N√§chstes einen \"chatbot\"-Knoten hinzu. Knoten repr√§sentieren Verarbeitungsschritte und sind normalerweise regul√§re Python-Funktionen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13090b18-61d4-4c7f-bc9c-3bcce865a947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever\n",
    "# the node is used.\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f329a0-1a1c-4c14-914b-fb134cdbe1d9",
   "metadata": {},
   "source": [
    "Beachte, dass die Funktion des Chatbot-Knotens den aktuellen Zustand als Eingabe akzeptiert und ein Dictionary zur√ºckgibt, das eine aktualisierte Nachrichtenliste unter dem Schl√ºssel ‚Äûmessages‚Äú enth√§lt. Dies ist das grundlegende Muster f√ºr alle LangGraph-Knotenfunktionen.\n",
    "\n",
    "Die add_messages-Funktion in unserem Zustand wird die Antwortmeldungen des LLM an die bereits im Zustand vorhandenen Nachrichten anh√§ngen.\n",
    "\n",
    "### N√§chster Schritt: Einstiegspunkt hinzuf√ºgen\n",
    "Um einen Einstiegspunkt f√ºr unseren Graphen zu erstellen, definieren wir eine Funktion, die als Startpunkt dient. Diese Funktion wird aufgerufen, wenn der Graph ausgef√ºhrt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c390330e-d071-4a87-8029-5e52468c0123",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_edge(START, \"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d307f5-d243-4175-9cec-7def51781d1a",
   "metadata": {},
   "source": [
    "Ebenso definieren wir einen Endpunkt. Dies weist den Graphen an: \"Wann immer dieser Knoten ausgef√ºhrt wird, kannst du den Chatbot beenden.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1a1fac-4b3c-463b-84b2-d0b25df36c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_edge(\"chatbot\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f25f06-78df-4f41-8ac6-0d6f690fb2db",
   "metadata": {},
   "source": [
    "Schlie√ülich m√∂chten wir in der Lage sein, unseren Graphen auszuf√ºhren. Dazu rufen wir `compile()` auf dem Graph-Builder auf. Dies erstellt einen **CompiledGraph**, den wir nutzen k√∂nnen, um unseren Zustand aufzurufen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afa21d4-2a0f-445d-a510-9e35a3bcd378",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328c0d77-767f-4f41-b73a-f61c182aaa35",
   "metadata": {},
   "source": [
    "Du kannst den Graphen mit der Methode `get_graph` und einer der \"draw\"-Methoden visualisieren, wie z.B. `draw_ascii` oder `draw_png`. Jede der Zeichnen-Methoden ben√∂tigt zus√§tzliche Abh√§ngigkeiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ead5f0-71dd-4b12-8bd9-d4964a1b7ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b50c0df-7d13-431a-ad4f-6bf02a3595f2",
   "metadata": {},
   "source": [
    "Jetzt lass uns den Chatbot ausf√ºhren!\n",
    "\n",
    "**Tipp**: Du kannst die Chat-Schleife jederzeit beenden, indem du \"quit\", \"exit\" oder \"q\" eintippst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582d06c7-74d6-4e08-b030-96329241f081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b28b029-2498-43cd-b838-2ab8bbfcdcb1",
   "metadata": {},
   "source": [
    "**Herzlichen Gl√ºckwunsch!** Du hast deinen ersten Chatbot mit LangGraph erstellt. Dieser Bot kann grundlegende Gespr√§che f√ºhren, indem er Benutzereingaben entgegennimmt und Antworten mit einem LLM generiert. Du kannst einen LangSmith Trace f√ºr den obigen Aufruf unter dem bereitgestellten Link einsehen.\n",
    "\n",
    "Allerdings hast du m√∂glicherweise bemerkt, dass das Wissen des Bots auf das beschr√§nkt ist, was in seinen Trainingsdaten enthalten ist. Im n√§chsten Teil werden wir ein Websuchtool hinzuf√ºgen, um das Wissen des Bots zu erweitern und ihn leistungsf√§higer zu machen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0927ad79-ddf0-4c86-9033-d294deea92db",
   "metadata": {},
   "source": [
    "# Teil 2: üõ†Ô∏è Verbesserung des Chatbots mit Werkzeugen\n",
    "\n",
    "Um Anfragen zu bearbeiten, die unser Chatbot \"aus dem Ged√§chtnis\" nicht beantworten kann, \n",
    "werden wir ein Websuchtool integrieren. \n",
    "Unser Bot kann dieses Werkzeug nutzen, um relevante Informationen zu finden und bessere Antworten zu geben.\n",
    "\n",
    "Wir benutzen daf√ºr die [Suchmaschine Tavily](https://python.langchain.com/docs/integrations/tools/tavily_search/), die wir leicht als `Tool` integrieren k√∂nnen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d632d06-ca95-4948-aac6-536d019b80ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "tool.invoke(\"Wann wird Friedrich Merz zum Bundeskanzler gew√§hlt?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8751d29-7198-4f49-9a48-212ff03312c5",
   "metadata": {},
   "source": [
    "Als N√§chstes erweitern wir unseren Graphen. \n",
    "Der folgende Code ist der gleiche wie in Teil 1, mit der Ausnahme, dass wir `bind_tools` zu unserem LLM hinzugef√ºgt haben. \n",
    "Dies informiert das LLM √ºber das korrekte JSON-Format, das verwendet werden soll, wenn es unsere Suchmaschine nutzen m√∂chte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477d5ad0-aff2-4022-b326-3166f69239d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# Modification: tell the LLM which tools it can call\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b83bc69-0636-4715-ae84-7968d6b997f6",
   "metadata": {},
   "source": [
    "Als N√§chstes m√ºssen wir eine Funktion erstellen, die die Werkzeuge tats√§chlich ausf√ºhrt, wenn sie aufgerufen werden. Dazu f√ºgen wir die Werkzeuge einem neuen Knoten hinzu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bc0f0a-be76-46ac-8918-8d1f734771d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79796ac8-0e94-4366-a340-7fc3c8926bb9",
   "metadata": {},
   "source": [
    "Die folgende Zelle zeigt den Aufbau des Chatbots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ec97cd-7e5a-405d-ae94-b87b1db59151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b115feb-d464-4347-8fba-f536f2c6ae3f",
   "metadata": {},
   "source": [
    "Und mit dem folgenden Code kannst Du ihn ausprobieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa083c32-343b-4b8d-ba52-865aa19953ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e519556-7fa2-4b24-90cc-3b926482979d",
   "metadata": {},
   "source": [
    "# Teil 3: Ein \"Ged√§chtnis\" f√ºr den Chatbot\n",
    "\n",
    "Unser Chatbot kann jetzt Werkzeuge verwenden, um Benutzerfragen zu beantworten, aber er erinnert sich nicht an den Kontext des Gespr√§chs. \n",
    "Dies schr√§nkt seine F√§higkeit ein, koh√§rente, mehrteilige Gespr√§che zu f√ºhren.\n",
    "\n",
    "LangGraph l√∂st dieses Problem durch das Zwischenspeichern des Gespr√§chs, das *CheckPointing*. Wenn du einen Checkpointer beim Kompilieren des Graphen bereitstellst und eine `thread_id` beim Aufruf deines Graphen verwendest, speichert LangGraph automatisch den Zustand nach jedem Schritt. Wenn du den Graph erneut mit der gleichen `thread_id` aufrufst, l√§dt der Graph seinen gespeicherten Zustand, sodass der Chatbot dort fortfahren kann, wo er aufgeh√∂rt hat.\n",
    "\n",
    "Wir werden sp√§ter sehen, dass Checkpointing viel leistungsf√§higer ist als einfaches Chat-Ged√§chtnis ‚Äì es erm√∂glicht dir, komplexe Zust√§nde jederzeit f√ºr Fehlerwiederherstellung, menschliche Beteiligung in Arbeitsabl√§ufen, Zeitreisen und mehr zu speichern und wiederherzustellen. Aber bevor wir uns zu weit vorausbegeben, lass uns Checkpointing hinzuf√ºgen, um mehrteilige Gespr√§che zu erm√∂glichen.\n",
    "\n",
    "Um zu beginnen, erstelle einen `MemorySaver`-Checkpointer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee56bb24-2152-4c06-bd48-37d51a59dd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729a433c-a816-406b-b977-4b9aaef8f571",
   "metadata": {},
   "source": [
    "Wir geben jetzt die Id der Unterhaltung als `thread_id` in der Konfiguration `config` mit.\n",
    "Diese wird jeweils bei der Verarbeitung (`graph.stream()`) mitgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d481aa9d-7d7a-4d41-a915-3cb39db34a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b644a82f-5a50-4a9e-88ec-34742c868438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    events = graph.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "        config,\n",
    "        stream_mode=\"values\",\n",
    "    )\n",
    "    for event in events:\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a336f3-71cc-4afe-9c9c-1a140718b2c6",
   "metadata": {},
   "source": [
    "# Teil 4: Abruf von Informationen\n",
    "\n",
    "In diesem Abschnitt werden wir uns mit dem Retrieval (Abruf) von Informationen befassen, um die F√§higkeiten unseres Chatbots weiter auszubauen. W√§hrend unser Chatbot bereits in der Lage ist, grundlegende Antworten zu geben und auf Webanfragen zu reagieren, m√∂chten wir ihm nun die M√∂glichkeit geben, gezielt Informationen aus einem `VectorStore` abzurufen. \n",
    "\n",
    "Durch die Integration von Retrieval-Techniken kann der Chatbot relevante Dokumente finden und pr√§zise Antworten auf Benutzeranfragen geben, indem er verwertbare Informationen nutzt, die in den gespeicherten Daten gespeichert sind. \n",
    "\n",
    "## Was ist ein VectorStore?\n",
    "\n",
    "Ein **VectorStore** ist wie ein gro√ües, digitales B√ºcherregal f√ºr Informationen, das sich gut merken kann, was es gespeichert hat. Hier sind ein paar einfache Punkte, um es besser zu verstehen:\n",
    "\n",
    "1. **Speicherort f√ºr Daten**: Stell dir vor, du hast viele verschiedene B√ºcher oder Dokumente mit Informationen. Ein VectorStore ist der Ort, an dem diese Informationen sicher gespeichert werden.\n",
    "\n",
    "2. **Verst√§dnis von Bedeutungen**: Anstatt nur Worte zu speichern, \"versteht\" ein VectorStore die Bedeutung dieser Worte. Es wandelt Informationen in \"Vektoren\" um, die wie Punkte im Raum sind. Dadurch kann er √§hnliche Informationen leicht finden.\n",
    "\n",
    "3. **Schnelles Finden**: Wenn du etwas suchst, kann der VectorStore schnell die richtigen Informationen herausfinden, so wie ein Bibliothekar dir das richtige Buch in der Bibliothek zeigen w√ºrde.\n",
    "\n",
    "4. **Helfer f√ºr Chatbots**: F√ºr einen Chatbot bedeutet ein VectorStore, dass er bei Fragen auf eine gro√üe Sammlung von Wissen zugreifen kann. Wenn du zum Beispiel nach Informationen zu einem bestimmten Thema fragst, kann der Chatbot schnell die besten Antworten finden, weil er in diesem speziellen Speicher nachsehen kann.\n",
    "\n",
    "Zusammengefasst: Ein VectorStore ist ein smarter Speicher f√ºr Informationen, der es einem Chatbot erm√∂glicht, schnell Antworten zu finden und dir bei deinen Fragen zu helfen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95da83e7-a656-421e-94e1-d46b48c65309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd149c0b-6f42-4363-a64d-df99f91ca5f7",
   "metadata": {},
   "source": [
    "## Laden des `VectorStore`\n",
    "\n",
    "Die \"Bef√ºllung\" des `VectorStore` ist in das Notebook [create_chroma](./chreate_chroma.ipynb) ausgelagert, da dieser Vorgang l√§nger dauert (und Geld kostet, da wir die Vektoren zu den Dokumenten mithilfe von OpenAI erstellen).\n",
    "\n",
    "Hier laden wir die von dort erstellte Vektordatenbank:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15a0875-6391-48e3-ade3-bfd5d7d97388",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "chromadb.configure(allow_reset=True)\n",
    "\n",
    "client = chromadb.PersistentClient(path=\"./chroma\")\n",
    "\n",
    "vector_store = Chroma(\n",
    "    client=client,\n",
    "    collection_name=\"Koalitionsvertrag\",\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9d45b8-3ec6-49e5-8b21-e08eab916f34",
   "metadata": {},
   "source": [
    "## Dokumentensuche als Werkzeug\n",
    "\n",
    "Wir f√ºgen die Suche im Koalitionsvertrag jetzt wie die Websuche als Tool hinzu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aa7979-9f80-4f3d-859d-745aa4924b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "retriever_tool = create_retriever_tool(retriever, \"Koalitionsvertrag\", \"Durchsuche dem Koalitionsvertrag von CDU und SPD\")\n",
    "search_tool = TavilySearchResults(max_results=2)\n",
    "tools = [search_tool, retriever_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5b4fc4-3529-41c6-96db-d967c0efcf1e",
   "metadata": {},
   "source": [
    "Wie schon vorher bauen die Werzeuge in den Chatbot-Graphen ein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06167ce8-1877-44f7-b7b5-de036fec84a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# Modification: tell the LLM which tools it can call\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383500c1-f5d1-4289-a7af-aa3197b427c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb53de0-97e0-4851-8ee2-41743a133582",
   "metadata": {},
   "source": [
    "Der folgende Code erlaubt uns, den Chatbot zu testen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c53bfafa-796b-4611-a613-e83851d758de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What do you know about LangGraph?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What do you know about LangGraph?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (call_bzqVd0hCWmUueMPBnvD0NHlx)\n",
      " Call ID: call_bzqVd0hCWmUueMPBnvD0NHlx\n",
      "  Args:\n",
      "    query: LangGraph\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"LangGraph Quickstart - GitHub Pages\", \"url\": \"https://langchain-ai.github.io/langgraph/tutorials/introduction/\", \"content\": \"[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-9-1)Assistant: LangGraph is a library designed to help build stateful multi-agent applications using language models. It provides tools for creating workflows and state machines to coordinate multiple AI agents or language model interactions. LangGraph is built on top of LangChain, leveraging its components while adding graph-based coordination capabilities. It's particularly useful for developing more complex, [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-6)   LangGraph is a library designed for building stateful, multi-actor applications with Large Language Models (LLMs). It's particularly useful for creating agent and multi-agent workflows.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-8)2. Developer: [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-19)LangGraph is likely a framework or library designed specifically for creating AI agents with advanced capabilities. Here are a few points to consider based on this recommendation:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-20)\", \"score\": 0.9328032}, {\"title\": \"langchain-ai/langgraph: Build resilient language agents as graphs.\", \"url\": \"https://github.com/langchain-ai/langgraph\", \"content\": \"Note\\nLooking for the JS version? See the JS repo and the JS docs.\\nLangGraph ‚Äî used by Replit, Uber, LinkedIn, GitLab and more ‚Äî is a low-level orchestration framework for building controllable agents. While langchain provides integrations and composable components to streamline LLM application development, the LangGraph library enables agent orchestration ‚Äî offering customizable architectures, long-term memory, and human-in-the-loop to reliably handle complex tasks.\\nshell [...] LangGraph is built for developers who want to build powerful, adaptable AI agents. Developers choose LangGraph for: [...] While LangGraph is our open-source agent orchestration framework, enterprises that need scalable agent deployment can benefit from LangGraph Platform.\\nLangGraph Platform can help engineering teams:\", \"score\": 0.8991304}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph is a library designed for building stateful multi-agent applications using large language models (LLMs). Here are some key points about LangGraph:\n",
      "\n",
      "1. **Purpose**: It helps create complex workflows and state machines that coordinate the interactions of multiple AI agents or language models. This makes it particularly useful for developing more advanced AI applications.\n",
      "\n",
      "2. **Integration with LangChain**: LangGraph is built on top of the LangChain framework, which provides components for language model applications. LangGraph adds capabilities for graph-based coordination among agents.\n",
      "\n",
      "3. **Features**: \n",
      "   - It offers customizable architectures for creating controllable agents.\n",
      "   - Supports long-term memory for agents, enabling them to retain information over time.\n",
      "   - Allows for human-in-the-loop interactions, which can facilitate complex task handling.\n",
      "\n",
      "4. **Usage**: LangGraph is used by several notable organizations, including Replit, Uber, LinkedIn, and GitLab, indicating its credibility and effectiveness in the industry.\n",
      "\n",
      "5. **Target Audience**: The library is aimed at developers looking to build adaptable and powerful AI agents. There is also a LangGraph Platform available for enterprises needing scalable deployment of agent applications.\n",
      "\n",
      "For more detailed information, you can visit the [LangGraph Quickstart Guide](https://langchain-ai.github.io/langgraph/tutorials/introduction/) or the [GitHub repository](https://github.com/langchain-ai/langgraph).\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "def stream_graph_updates(user_input: str):\n",
    "    events = graph.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "        config,\n",
    "        stream_mode=\"values\",\n",
    "    )\n",
    "    for event in events:\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfdc009-67f2-42ed-9e1d-a65ab35ca3f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
